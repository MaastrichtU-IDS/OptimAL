{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree, ensemble\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.feature_selection import VarianceThreshold,SelectFromModel\n",
    "from sklearn import svm, linear_model, neighbors\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "import numpy\n",
    "from sklearn import model_selection\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import argparse\n",
    "import random\n",
    "import csv\n",
    "import numbers\n",
    "import gc\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics.scorer import _check_multimetric_scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createFeatureMat(pairs, classes, drug_df, disease_df, featureMatfile=None):\n",
    "    totalNumFeatures=drug_df.shape[1] + disease_df.shape[1]-2\n",
    "    drug_features = drug_df.columns.difference( ['Drug'] )\n",
    "    disease_features = disease_df.columns.difference( ['Disease'])\n",
    "    featureMatrix = numpy.empty((0,totalNumFeatures), int)\n",
    "    for pair,cls in zip(pairs,classes):\n",
    "        (dr,di)=pair\n",
    "        values1 = drug_df.loc[drug_df['Drug'] == dr][drug_features].values\n",
    "        values2 = disease_df.loc[disease_df['Disease']==di][disease_features].values\n",
    "        featureArray =numpy.append(values1,values2 )\n",
    "        featureMatrix=numpy.vstack([featureMatrix, featureArray])\n",
    "    return featureMatrix\n",
    "\n",
    "def multimetric_score(estimator, X_test, y_test, scorers):\n",
    "    \"\"\"Return a dict of score for multimetric scoring\"\"\"\n",
    "    scores = {}\n",
    "    for name, scorer in scorers.items():\n",
    "        if y_test is None:\n",
    "            score = scorer(estimator, X_test)\n",
    "        else:\n",
    "            score = scorer(estimator, X_test, y_test)\n",
    "\n",
    "        if hasattr(score, 'item'):\n",
    "            try:\n",
    "                # e.g. unwrap memmapped scalars\n",
    "                score = score.item()\n",
    "            except ValueError:\n",
    "                # non-scalar?\n",
    "                pass\n",
    "        scores[name] = score\n",
    "\n",
    "        if not isinstance(score, numbers.Number):\n",
    "            raise ValueError(\"scoring must return a number, got %s (%s) \"\n",
    "                             \"instead. (scorer=%s)\"\n",
    "                             % (str(score), type(score), name))\n",
    "    return scores\n",
    "\n",
    "def runModel( pairs, classes,  drug_df, disease_df , cv, n_subset, n_proportion, n_fold, model_type, model_fun, features, disjoint_cv, n_seed, n_setsel, verbose=True, output_f=None):\n",
    "    clf= get_classification_model(model_type, model_fun, n_seed)\n",
    "    all_auc = []\n",
    "    all_auprc = []\n",
    "    all_fs = []\n",
    "    le_drug = preprocessing.LabelEncoder()\n",
    "    le_dis = preprocessing.LabelEncoder()\n",
    "    le_drug.fit(pairs[:,0])\n",
    "    le_dis.fit(pairs[:,1])\n",
    "    \n",
    "    results = pd.DataFrame()\n",
    "\n",
    "    for i, (train, test) in enumerate(cv):\n",
    "        file_name = None # for saving results\n",
    "        pairs_train = pairs[train]\n",
    "        classes_train = classes[train]\n",
    "        pairs_test = pairs[test]\n",
    "        classes_test = classes[test]\n",
    "        \n",
    "        pairs_train_df = pd.DataFrame( list(zip(pairs[train,0],pairs[train,1],classes[train])),columns=['Drug','Disease','Class'])\n",
    "        train_df=pd.merge( pd.merge(drug_df,pairs_train_df, on='Drug'),disease_df,on='Disease')\n",
    "\n",
    "        train_df['Drug']=le_drug.transform(train_df['Drug'])\n",
    "        train_df['Disease']=le_dis.transform(train_df['Disease'])\n",
    "        features_cols= train_df.columns.difference(['Drug','Disease','Class'])\n",
    "        X=train_df[features_cols].values\n",
    "        y=train_df['Class'].values.ravel()\n",
    "\n",
    "        pairs_test_df = pd.DataFrame( list(zip(pairs[test,0],pairs[test,1],classes[test])),columns=['Drug','Disease','Class'])\n",
    "        test_df=pd.merge( pd.merge(drug_df,pairs_test_df, on='Drug'),disease_df,on='Disease')\n",
    "\n",
    "        test_df['Drug']=le_drug.transform(test_df['Drug'])\n",
    "        test_df['Disease']=le_dis.transform(test_df['Disease'])\n",
    "        features_cols= test_df.columns.difference(['Drug','Disease','Class'])\n",
    "        X_new=test_df[features_cols].values\n",
    "        y_new=test_df['Class'].values.ravel()\n",
    "        \n",
    "        clf.fit(X,y)\n",
    "\n",
    "        scoring = ['precision', 'recall', 'accuracy', 'roc_auc', 'f1', 'average_precision']\n",
    "        scorers, multimetric = metrics.scorer._check_multimetric_scoring(clf, scoring=scoring)\n",
    "        #print(scorers)\n",
    "        scores = multimetric_score(clf, X_new, y_new, scorers)\n",
    "        print (\"C1\",scores, file=output_f)\n",
    "        results = results.append(scores, ignore_index=True)  \n",
    "        del X, y\n",
    "        del X_new, y_new\n",
    "        del train_df, pairs_train_df\n",
    "        del test_df, pairs_test_df\n",
    "        gc.collect()\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "def getData(goldindfile, drugfeatfiles, diseasefeatfiles, selectedFeatures=None):\n",
    "    if selectedFeatures != None:\n",
    "        selectedFeatures += ['Drug','Disease']\n",
    "    \n",
    "    #Use delimiter with txt files, not with csv files. Remove delimiter with csv\n",
    "    gold_df= pd.read_csv(goldindfile, delimiter='\\t')\n",
    "\n",
    "    drugs=gold_df.Drug.unique()\n",
    "    diseases=gold_df.Disease.unique()\n",
    "\n",
    "    for i,featureFilename in enumerate(drugfeatfiles):\n",
    "        temp=pd.read_csv(featureFilename, delimiter='\\t')\n",
    "        if i != 0:\n",
    "            drug_df=drug_df.merge(temp,on='Drug')\n",
    "            #drug_df=drug_df.merge(temp,how='outer',on='Drug')\n",
    "        else:\n",
    "            drug_df =temp\n",
    "\n",
    "    #drug_df.fillna(0,inplace=True)\n",
    "\n",
    "    \n",
    "    #If feature selection is used, then removes all non-selected features from drug_df\n",
    "    if selectedFeatures != None:\n",
    "        drug_feature_names = drug_df.columns.intersection(selectedFeatures)\n",
    "        drug_df=drug_df[drug_feature_names]\n",
    "\n",
    "    for i,featureFilename in enumerate(diseasefeatfiles):\n",
    "        temp=pd.read_csv(featureFilename, delimiter='\\t')\n",
    "        if i != 0:\n",
    "            disease_df=disease_df.merge(temp,on='Disease')\n",
    "        else:\n",
    "            disease_df =temp\n",
    "    \n",
    "    #If feature selection is used, then removes all non-selected features from disease_df\n",
    "    if selectedFeatures != None:\n",
    "        disease_feature_names = disease_df.columns.intersection(selectedFeatures)\n",
    "        disease_df=disease_df[disease_feature_names]\n",
    "\n",
    "    print (\"number of drugs \",len(drug_df))\n",
    "    print (\"number of diseases \",len( disease_df))\n",
    "    commonDrugs=set(drug_df['Drug'].unique()).intersection(set(drugs))\n",
    "    commonDiseases=set(disease_df['Disease'].unique()).intersection(set(diseases))\n",
    "\n",
    "    gold_df=gold_df.loc[gold_df['Drug'].isin(commonDrugs) & gold_df['Disease'].isin(commonDiseases) ] \n",
    "    drug_df=drug_df.loc[drug_df['Drug'].isin(gold_df.Drug.unique())]\n",
    "    disease_df=disease_df.loc[disease_df['Disease'].isin(gold_df.Disease.unique())]\n",
    "    print (\"#drugs in gold \",len( drugs))\n",
    "    print (\"#diseases in gold \",len( diseases))\n",
    "    print (\"Used indications \",len(gold_df))\n",
    "    print (\"# of disease features\", len(disease_df.columns))\n",
    "    print (\"# of drug features\", len(drug_df.columns))\n",
    "       \n",
    "    return gold_df, drug_df, disease_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_groups(idx_true_list, idx_false_list, n_subset, n_proportion=1, shuffle=False):\n",
    "    \"\"\"\n",
    "    >>> a = get_groups([[13,2,1],[14,3,4],[15,5,6]], [[7,8],[9,10],[11,12]], 1, 1, True)\n",
    "    \"\"\"\n",
    "    n = len(idx_true_list)\n",
    "    if n_subset != -1:\n",
    "        n_subset = n_subset / n \n",
    "    for i in range(n):\n",
    "        if n_subset == -1: # use all data\n",
    "            if n_proportion < 1:\n",
    "                indices_test = idx_true_list[i] + idx_false_list[i]\n",
    "            else:\n",
    "                indices_test = idx_true_list[i] + random.sample( idx_false_list[i], n_proportion * len(idx_true_list[i]))\n",
    "        else:\n",
    "            if shuffle:\n",
    "                indices_test = random.sample(idx_true_list[i], n_subset) + random.sample(idx_false_list[i], n_proportion * n_subset)\n",
    "            else:\n",
    "                indices_test = idx_true_list[i][:n_subset] + idx_false_list[i][:(n_proportion * n_subset)]\n",
    "        indices_train = []\n",
    "        for j in range(n):\n",
    "            if i == j:\n",
    "                continue\n",
    "            if n_subset == -1: # use all data\n",
    "                if n_proportion < 1:\n",
    "                    indices_train += idx_true_list[j] + idx_false_list[j]\n",
    "                else:\n",
    "                    indices_train += idx_true_list[j] + random.sample( idx_false_list[j], n_proportion * len(idx_true_list[j]))\n",
    "            else:\n",
    "                if shuffle:\n",
    "                    indices_train += random.sample(idx_true_list[j], n_subset) + random.sample(idx_false_list[j], n_proportion * n_subset)\n",
    "                else:\n",
    "                    indices_train += idx_true_list[j][:n_subset] + idx_false_list[j][:(n_proportion * n_subset)]\n",
    "        yield indices_train, indices_test\n",
    " \n",
    "def balance_data_and_get_cv(pairs, classes, n_fold, n_proportion, n_subset=-1, disjoint=False, n_seed = None):\n",
    "    \"\"\"\n",
    "    pairs: all possible drug-disease pairs\n",
    "    classes: labels of these drug-disease associations (1: known, 0: unknown)\n",
    "    n_fold: number of cross-validation folds\n",
    "    n_proportion: proportion of negative instances compared to positives (e.g.,\n",
    "    2 means for each positive instance there are 2 negative instances)\n",
    "    n_subset: if not -1, it uses a random subset of size n_subset of the positive instances\n",
    "    (to reduce the computational time for large data sets)\n",
    "    disjoint: whether the cross-validation folds contain overlapping drugs (True) \n",
    "    or not (False)\n",
    "    This function returns (pairs, classes, cv) after balancing the data and\n",
    "    creating the cross-validation folds. cv is the cross validation iterator containing \n",
    "    train and test splits defined by the indices corresponding to elements in the \n",
    "    pairs and classes lists.\n",
    "    \"\"\"\n",
    "    classes = numpy.array(classes)\n",
    "    pairs = numpy.array(pairs)\n",
    "    idx_true_list = [ list() for i in range(n_fold) ]\n",
    "    idx_false_list = [ list() for i in range(n_fold) ]\n",
    "    if disjoint:\n",
    "        i_random = random.randint(0,100) # for getting the shuffled drug names in the same fold below\n",
    "        for idx, (pair, class_) in enumerate(zip(pairs, classes)):\n",
    "            drug, disease = pair\n",
    "            if disjoint == 1:\n",
    "                i = sum([ord(c) + i_random for c in drug]) % n_fold\n",
    "            else:\n",
    "                i = sum([ord(c) + i_random for c in disease]) % n_fold\n",
    "            if class_ == 0:\n",
    "                idx_false_list[i].append(idx)\n",
    "            else:\n",
    "                idx_true_list[i].append(idx)\n",
    "        #print \"+/-:\", map(len, idx_true_list), map(len, idx_false_list),n_fold,n_proportion, n_subset\n",
    "        cv = get_groups(idx_true_list, idx_false_list, n_subset, n_proportion, shuffle=True)\n",
    "    else:\n",
    "        indices_true = numpy.where(classes == 1)[0]\n",
    "        indices_false = numpy.where(classes == 0)[0]\n",
    "        if n_subset == -1: # use all data\n",
    "            n_subset = len(classes)\n",
    "        indices_true = indices_true[:n_subset]\n",
    "        numpy.random.shuffle(indices_false)\n",
    "        if n_proportion < 1:\n",
    "            indices = indices_false\n",
    "        else:\n",
    "            #indices = numpy.random.choice(indices_false,size=(n_proportion*indices_true.shape[0]))\n",
    "            indices = indices_false[:(n_proportion*indices_true.shape[0])]\n",
    "        #print \"+/-:\", len(indices_true), len(indices), len(indices_false)\n",
    "        pairs = numpy.concatenate((pairs[indices_true], pairs[indices]), axis=0)\n",
    "        classes = numpy.concatenate((classes[indices_true], classes[indices]), axis=0) \n",
    "        skf = model_selection.StratifiedKFold( n_splits=n_fold, shuffle=True, random_state=n_seed)\n",
    "        cv= skf.split(pairs, classes)\n",
    "    return pairs, classes, cv\n",
    "\n",
    "def get_classification_model(model_type, model_fun = None, n_seed = None):\n",
    "    \"\"\"\n",
    "    model_type: custom | svm | logistic | knn | tree | rf | gbc\n",
    "    model_fun: the function implementing classifier when the model_type is custom\n",
    "    The allowed values for model_type are custom, svm, logistic, knn, tree, rf, gbc\n",
    "    corresponding to custom model provided in model_fun by the user or the default \n",
    "    models in Scikit-learn for support vector machine, k-nearest-neighbor, \n",
    "    decision tree, random forest and gradient boosting classifiers, respectively. \n",
    "    Returns the classifier object that provides fit and predict_proba methods.\n",
    "    \"\"\"\n",
    "    if model_type == \"svm\":\n",
    "        clf = svm.SVC(kernel='linear', probability=True, C=1)\n",
    "    elif model_type == \"logistic\":\n",
    "        clf = linear_model.LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, random_state=n_seed) #, fit_intercept=True, intercept_scaling=1, class_weight=None, solver='liblinear', max_iter=100, multi_class='ovr', verbose=0, warm_start=False, n_jobs=1)\n",
    "    elif model_type == \"knn\":\n",
    "        clf = neighbors.KNeighborsClassifier(n_neighbors=5) #weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=1)\n",
    "    elif model_type == \"tree\":\n",
    "        clf = tree.DecisionTreeClassifier(criterion='gini', random_state=n_seed) #splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, max_leaf_nodes=None, class_weight=None, presort=False)\n",
    "    elif model_type == \"rf\":\n",
    "        clf = ensemble.RandomForestClassifier(n_estimators=100, criterion='gini', random_state=n_seed) #, max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, bootstrap=True, oob_score=False, n_jobs=1, verbose=0, warm_start=False, class_weight=None)\n",
    "    elif model_type == \"gbc\":\n",
    "        clf = ensemble.GradientBoostingClassifier(n_estimators= 100, max_depth= 5, random_state = n_seed, max_features=0.9)\n",
    "        #clf = ensemble.GradientBoostingClassifier(n_estimators=100, loss='deviance', learning_rate=0.1, subsample=1.0, random_state=n_seed) #, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, init=None, max_features=None, verbose=0, max_leaf_nodes=None, warm_start=False, presort='auto')\n",
    "    elif model_type == \"custom\":\n",
    "        if fun is None:\n",
    "            raise ValueError(\"Custom model requires fun argument to be defined!\")\n",
    "        clf = fun\n",
    "    else:\n",
    "        raise ValueError(\"Uknown model type: %s!\" % model_type)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    \n",
    "    goldindfile=args[\"goldindications\"]\n",
    "    model_type=args[\"modelfile\"]\n",
    "    disjoint=int(args[\"disjoint\"])\n",
    "    output_file_name=args[\"output\"]\n",
    "    drugfeatfiles=args[\"drugfeat\"]\n",
    "    diseasefeatfiles=args[\"diseasefeat\"]\n",
    "    n_proportion = int(args[\"proportion\"])\n",
    "    #Get parameters\n",
    "    n_seed = 205\n",
    "    #random.seed(n_seed) # for reproducibility\n",
    "    n_subset =-1\n",
    "\n",
    "    output_file=open( output_file_name,'a')\n",
    "\n",
    "    #No feature selection\n",
    "    selectedFeatures =None\n",
    "    \n",
    "    #with feature selection\n",
    "    df_sf = pd.read_csv('data/output/selected_features.csv')\n",
    "    selectedFeatures = list(df_sf['feature'])\n",
    "    \n",
    "    #Gets goldstandard data and binary feature matrix for both the indicated drug and disease files\n",
    "    gold_df, drug_df, disease_df = getData(goldindfile, drugfeatfiles, diseasefeatfiles, selectedFeatures)\n",
    "    \n",
    "    features=[ fn[fn.index('-')+1:fn.index('.txt')] for fn in drugfeatfiles+diseasefeatfiles]\n",
    "\n",
    "    \n",
    "    drugDiseaseKnown = set([tuple(x) for x in  gold_df[['Drug','Disease']].values])\n",
    "\n",
    "    commonDrugs=drug_df['Drug'].unique()\n",
    "    commonDiseases=disease_df['Disease'].unique()\n",
    "    pairs=[]\n",
    "    classes=[]\n",
    "    print (\"commonDiseases\",len(commonDiseases))\n",
    "    print (\"commonDrugs\",len(commonDrugs))\n",
    "    for dr in commonDrugs:\n",
    "        for di in commonDiseases:\n",
    "            if (dr,di)  in drugDiseaseKnown:\n",
    "                cls=1\n",
    "            else:\n",
    "                cls=0\n",
    "            pairs.append((dr,di))\n",
    "            classes.append(cls)\n",
    "\n",
    "    n_run = 10\n",
    "    n_seed = 205\n",
    "    n_fold =10\n",
    "    model_fun=None\n",
    "    n_subset=-1\n",
    "\n",
    "    results_runs = pd.DataFrame()\n",
    "    output_file.write(\"n_fold\\tn_proportion\\tn_setsel\\tmodel type\\tfeatures\\tdisjoint\\tauc.mean\\tauc.sd\\tauprc.mean\\tauprc.sd\\tf-score.mean\\tf-score.sd\\n\")\n",
    "    for i in range(n_run):\n",
    "        if n_seed is not None:\n",
    "            n_seed += i\n",
    "            random.seed(n_seed)\n",
    "            numpy.random.seed(n_seed)\n",
    "        pairs_, classes_, cv = balance_data_and_get_cv(pairs, classes, n_fold, n_proportion, n_subset, disjoint, n_seed )\n",
    "        results = runModel( pairs_, classes_, drug_df, disease_df, cv, n_subset, n_proportion, n_fold, model_type, model_fun, features, disjoint, n_seed, 1, verbose=True, output_f=output_file)\n",
    "        results_runs = results_runs.append(results.mean(), ignore_index=True)\n",
    "        print ('Run ',i,results.mean())\n",
    "    print (\"Runs\",results_runs.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of drugs  816\n",
      "number of diseases  1393\n",
      "#drugs in gold  1594\n",
      "#diseases in gold  1611\n",
      "Used indications  4715\n",
      "# of disease features 73\n",
      "# of drug features 29\n",
      "commonDiseases 1103\n",
      "commonDrugs 788\n",
      "Run  0 accuracy             0.778188\n",
      "average_precision    0.709832\n",
      "f1                   0.602383\n",
      "precision            0.746373\n",
      "recall               0.507891\n",
      "roc_auc              0.787664\n",
      "dtype: float64\n",
      "Run  1 accuracy             0.770343\n",
      "average_precision    0.704608\n",
      "f1                   0.590185\n",
      "precision            0.724442\n",
      "recall               0.500765\n",
      "roc_auc              0.785215\n",
      "dtype: float64\n",
      "Run  2 accuracy             0.776448\n",
      "average_precision    0.714817\n",
      "f1                   0.599733\n",
      "precision            0.741756\n",
      "recall               0.505973\n",
      "roc_auc              0.788818\n",
      "dtype: float64\n",
      "Run  3 accuracy             0.770194\n",
      "average_precision    0.701435\n",
      "f1                   0.592674\n",
      "precision            0.721607\n",
      "recall               0.505121\n",
      "roc_auc              0.786477\n",
      "dtype: float64\n",
      "Run  4 accuracy             0.775660\n",
      "average_precision    0.713312\n",
      "f1                   0.596839\n",
      "precision            0.741110\n",
      "recall               0.501497\n",
      "roc_auc              0.784877\n",
      "dtype: float64\n",
      "Run  5 accuracy             0.773650\n",
      "average_precision    0.705529\n",
      "f1                   0.593736\n",
      "precision            0.734816\n",
      "recall               0.500122\n",
      "roc_auc              0.784962\n",
      "dtype: float64\n",
      "Run  6 accuracy             0.774792\n",
      "average_precision    0.711990\n",
      "f1                   0.597616\n",
      "precision            0.736608\n",
      "recall               0.505671\n",
      "roc_auc              0.788740\n",
      "dtype: float64\n",
      "Run  7 accuracy             0.775570\n",
      "average_precision    0.709052\n",
      "f1                   0.596558\n",
      "precision            0.741115\n",
      "recall               0.501668\n",
      "roc_auc              0.788530\n",
      "dtype: float64\n",
      "Run  8 accuracy             0.774789\n",
      "average_precision    0.703536\n",
      "f1                   0.596589\n",
      "precision            0.738508\n",
      "recall               0.503601\n",
      "roc_auc              0.786287\n",
      "dtype: float64\n",
      "Run  9 accuracy             0.772995\n",
      "average_precision    0.703444\n",
      "f1                   0.595151\n",
      "precision            0.731168\n",
      "recall               0.503845\n",
      "roc_auc              0.784755\n",
      "dtype: float64\n",
      "Runs accuracy             0.774263\n",
      "average_precision    0.707756\n",
      "f1                   0.596146\n",
      "precision            0.735750\n",
      "recall               0.503615\n",
      "roc_auc              0.786633\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "args = dict()\n",
    "args[\"goldindications\"] = \"data/input/unified-gold-standard-umls.txt\" \n",
    "args[\"modelfile\"] = \"rf\"\n",
    "args[\"disjoint\"] = 1\n",
    "args[\"output\"] = \"data/output/completeset_unified_validation.txt\"\n",
    "args[\"drugfeat\"] = [\"data/features/drugs-targets.txt\",\"data/features/drugs-fingerprint.txt\",\"data/features/drugs-sider-se.txt\"]\n",
    "args[\"diseasefeat\"] = [\"data/features/diseases-ndfrt-meddra.txt\"]\n",
    "args[\"proportion\"]= 2\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
