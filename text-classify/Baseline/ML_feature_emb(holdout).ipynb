{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_data set\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_data = pd.read_csv('crowd_final.csv')\n",
    "test_data = pd.read_csv('experts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rep(text):\n",
    "    a = text.replace('Indication: Treatment', 'treatment')\n",
    "    b = a.replace('Contraindication', 'contraindication')\n",
    "    c = b.replace('Indication: Symptomatic Relief', 'relief')\n",
    "    d = c.replace('Effect', 'effect')\n",
    "    return d\n",
    "\n",
    "def rep2(text):\n",
    "    a = text.replace('INDICATION AND USAGE', '')\n",
    "\n",
    "    return a\n",
    "\n",
    "def lower (x):\n",
    "    return x.lower()\n",
    "\n",
    "\n",
    "# Functions for cleaning \n",
    "\n",
    "def remove (x):\n",
    "    no_punct = \"\"\n",
    "    for char in x:\n",
    "            if char in '''qwertyuiopasdfghjklzxcvbnmQWERTYUIOPASDFGHJKLZXCVBNM ''':\n",
    "                    no_punct = no_punct + char\n",
    "    return no_punct\n",
    "\n",
    "def remove_non_digits (x):\n",
    "    no_punct = \"\"\n",
    "    for char in x:\n",
    "            if char in '''1234567890qwertyuiopasdfghjklzxcvbnmQWERTYUIOPASDFGHJKLZXCVBNM ''':\n",
    "                    no_punct = no_punct + char\n",
    "    return no_punct\n",
    "\n",
    "def lower (x):\n",
    "    return x.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107    NaN\n",
      "Name: context, dtype: object\n",
      "Series([], Name: disease_name, dtype: object)\n",
      "Series([], Name: expert_consensus, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "print(test_data[test_data['context'].isnull()]['context'])\n",
    "print(test_data[test_data['disease_name'].isnull()]['disease_name'])\n",
    "print(test_data[test_data['expert_consensus'].isnull()]['expert_consensus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.drop(test_data.index[107]).reset_index()\n",
    "\n",
    "test_data['expert_consensus'] = test_data['expert_consensus'].apply(rep)\n",
    "test_data['disease_name'] = test_data['disease_name'].apply(lower)\n",
    "test_data['drug_name'] = test_data['drug_name'].apply(lower)\n",
    "test_data['context'] = test_data['context'].apply(lower)\n",
    "test_data['context'] = test_data['context'].apply(remove_non_digits)\n",
    "\n",
    "test_data = test_data[test_data['expert_consensus'] != 'No consensus'].reset_index()\n",
    "test_data = test_data[['context', 'do_id', 'disease_name','drug_id','drug_name', 'expert_consensus' ]]\n",
    "test_data = test_data.rename(columns={\"context\": \"text\", \"do_id\": \"disease\",  \"drug_id\": \"drug\", \"expert_consensus\": \"label\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: text, dtype: object)\n",
      "Series([], Name: relation, dtype: object)\n",
      "Series([], Name: disease, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "print(train_data[train_data['text'].isnull()]['text'])\n",
    "print(train_data[train_data['relation'].isnull()]['relation'])\n",
    "print(train_data[train_data['disease'].isnull()]['disease'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['text'] = train_data['text'].apply(rep2)\n",
    "train_data['text'] = train_data['text'].apply(lower)\n",
    "train_data['drug'] = train_data['drug'].apply(lower)\n",
    "train_data['disease'] = train_data['disease'].apply(lower)\n",
    "test_data['text'] = test_data['text'].apply(remove_non_digits)\n",
    "train_data = train_data[train_data['relation'] != 'IDK'].reset_index()\n",
    "train_data = train_data[['text', 'DOID','disease', 'DBID','drug', 'relation' ]]\n",
    "train_data = train_data.rename(columns={ \"DOID\": \"disease\",\"disease\": \"disease_name\",  \"DBID\": \"drug\", \"drug\": \"drug_name\", \"relation\": \"label\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge them to have consistent encoding \n",
    "frames = [train_data, test_data]\n",
    "\n",
    "merged_data = pd.concat(frames).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = merged_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels \n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "le.fit(data['label'])\n",
    "le.classes_\n",
    "labels_en = le.transform(data['label']) \n",
    "\n",
    "# --- Encode Disease ---\n",
    "\n",
    "le.fit(data['disease'])\n",
    "le.classes_\n",
    "disease_encoded = le.transform(data['disease'])\n",
    "\n",
    "# --- Encode Drugs ---\n",
    "\n",
    "le.fit(data['drug'])\n",
    "le.classes_\n",
    "drug_encoded = le.transform(data['drug']) \n",
    "\n",
    "# --- Remove stop words and clean the Text ---\n",
    "data['text'] = data['text'].apply(remove)\n",
    "data['text'] = data['text'].apply(lower)\n",
    "\n",
    "# The final Set\n",
    "\n",
    "d = {'index':data['index'], 'label': labels_en, 'text': data['text'],'disease_name': data['disease_name'],  'disease': disease_encoded, 'drug':drug_encoded, 'drug_name':data['drug_name'] }\n",
    "df = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The rule phrases\n",
    "\n",
    "phrases =  [\"hypersensitivity reactions\",\n",
    "\"associated with the risk of\",\n",
    "\"to the risk of\",\n",
    "\"a high risk for\",\n",
    "\"a high risk of\",\n",
    "\"high incidence of\", \n",
    "\"higher incidence of\", \n",
    "\" cause \",\n",
    "\" causes \",\n",
    "\"symptoms occure\",\n",
    "\"teratogenic\",\n",
    "\"site reaction\",\n",
    "\"the risk of development\",\n",
    "\"is associated with a risk of\",\n",
    "\"symptoms of the poisoning\",\n",
    "\"symptoms of poisoning\" ,\n",
    "\"not administrated to\",\n",
    "\"contraindicated in\",\n",
    "\"contraindicatedin\",\n",
    "\"should not be used\",\n",
    "\"is contraindication for\",\n",
    "\"is contraindication when\",\n",
    "\"is contraindicated when\",\n",
    "\"must not be used for\",\n",
    "\"do not administer\",\n",
    "\"should not initiate\",\n",
    "\"not be administered to\",\n",
    "\"do not initiate patients\",\n",
    "\"contraindication for\",\n",
    "\"should not be given\",\n",
    "\"do not use\",\n",
    "\"patients with a history of\",\n",
    "\"relief of the signs\",\n",
    "\"relief of the signs and symptoms of\",\n",
    "\"relief of signs\",\n",
    "\"relief of symptoms\",\n",
    "\"relief of the symptoms\",\n",
    "\"help\",\n",
    "\"helps\",\n",
    "\"relief of signs and symptoms of\",\n",
    "\"reduction of symptoms of\",\n",
    "\"treatment of the symptoms of\",\n",
    "\"for the relief\",\n",
    "\"management of the signs and symptoms of\", \n",
    "\" indicated for the treatment of\",\n",
    "\" indicated in the management of\",\n",
    "\" indicated for the management of\",\n",
    "\"for the management of\",\n",
    "\"management of\",\n",
    "\" indicated for the maintenance of remission\", \n",
    "\"or the treatment of\",\n",
    "\"in the treatment of\",\n",
    "\" indicated as\",\n",
    "\" indicated in\",\n",
    "\"be effective\",\n",
    "\"active treatment of\",\n",
    "\" indicated for\",\n",
    "\"treatment of\",\n",
    "\" indicated as an adjunct\",\n",
    "\" indicated for use in the treatment of\", \n",
    "\" indicated for the intermittent treatment\", \n",
    "\" indicated to reduce the rate of\",\n",
    "\" indicated for the rapid control\",\n",
    "\" indicated for the control\",\n",
    "\"reduce the risk of\",\n",
    "\" indicated as adjunctive treatment\",\n",
    "\"for the treatment of\",\n",
    "\" indicated as an adjunct\",\n",
    "\"areindicatedas\",\n",
    "\"treatment is indicated\",\n",
    "\"prophylaxis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the features as distances of disease from each rule phrase\n",
    "def get_features (text, disease):\n",
    "    str = text\n",
    "    position_disease = str.find(disease)\n",
    "    \n",
    "    feature = []\n",
    "    for i in range(len(phrases)):\n",
    "        position_phrase = str.find(phrases[i])\n",
    "        if position_phrase != -1:\n",
    "            distance = abs(position_disease - position_phrase)\n",
    "            feature.append(distance)\n",
    "        else:\n",
    "            feature.append(0)\n",
    "    return feature\n",
    "\n",
    "\n",
    "def collect_features(df):\n",
    "    X_features =[]\n",
    "    for i in range(len(df)):\n",
    "        new_feature = get_features (df['text'][i], df['disease_name'][i])\n",
    "        X_features.append(new_feature)\n",
    "    return X_features\n",
    "\n",
    "X_features = collect_features(data)\n",
    "y = labels_en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          0\n",
       "1          1\n",
       "2          2\n",
       "3          3\n",
       "4          4\n",
       "        ... \n",
       "3575    3575\n",
       "3576    3576\n",
       "3577    3577\n",
       "3578    3578\n",
       "3579       0\n",
       "Name: index, Length: 3580, dtype: int64"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['index'][0:3580]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm \n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import pycm\n",
    "from pycm import *\n",
    "\n",
    "\n",
    "X = X_features\n",
    "\n",
    "X_train, X_test = X[0:3579], X[3580:]\n",
    "y_train, y_test = y[0:3579], y[3580:]\n",
    "\n",
    "class_weight = dict({0:4, 1:5, 2:4, 3:1})\n",
    "#, class_weight = class_weight\n",
    "\n",
    "\n",
    "model = svm.SVC(gamma= 'scale')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "cm = ConfusionMatrix(y_pred, y_test)\n",
    "confusion_matrix = pd.DataFrame(data=cm.table)\n",
    "confusion_matrix.columns=['Contraindication', 'Effect', 'Relief', 'Treatment']\n",
    "confusion_matrix.index = ['Contraindication', 'Effect', 'Relief', 'Treatment']\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics from confusion matrix\n",
    "FP = confusion_matrix.sum(axis=0) - np.diag(confusion_matrix)  \n",
    "FN = confusion_matrix.sum(axis=1) - np.diag(confusion_matrix)\n",
    "TP = np.diag(confusion_matrix)\n",
    "TN = confusion_matrix.values.sum() - (FP + FN + TP)\n",
    "\n",
    "# Overall accuracy\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "PRE = (TP)/(TP+FP)\n",
    "REC = (TP)/(TP+FN)\n",
    "F1 = 2*(TP)/(2*TP+FP+FN)\n",
    "\n",
    "\n",
    "print('---Accuracy---')\n",
    "print(ACC)\n",
    "print('---Precision---')\n",
    "print(PRE)\n",
    "print('---Recall---')\n",
    "print(REC)\n",
    "print('---F1-score---')\n",
    "print(F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mistakes  = FP.sum()\n",
    "mistakes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from pycm import *\n",
    "\n",
    "dt_model = DecisionTreeClassifier()\n",
    "\n",
    "X = X_features\n",
    "\n",
    "X_train, X_test = X[0:3579], X[3580:]\n",
    "y_train, y_test = y[0:3579], y[3580:]\n",
    "\n",
    "class_weight = dict({0:4, 1:5, 2:4, 3:1})\n",
    "    #, class_weight = class_weight\n",
    "    \n",
    "dt_model = DecisionTreeClassifier( criterion = 'entropy', random_state = 42, class_weight = class_weight)\n",
    "dt_model = dt_model.fit(X_train, y_train)\n",
    "    \n",
    "y_pred = dt_model.predict(X_test)\n",
    "\n",
    "cm = ConfusionMatrix(y_test, y_pred)\n",
    "\n",
    "confusion_matrix = pd.DataFrame(data=cm.table)\n",
    "confusion_matrix.columns=['Contraindication', 'Effect', 'Relief', 'Treatment']\n",
    "confusion_matrix.index = ['Contraindication', 'Effect', 'Relief', 'Treatment']\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics from confusion matrix\n",
    "FP = confusion_matrix.sum(axis=0) - np.diag(confusion_matrix)  \n",
    "FN = confusion_matrix.sum(axis=1) - np.diag(confusion_matrix)\n",
    "TP = np.diag(confusion_matrix)\n",
    "TN = confusion_matrix.values.sum() - (FP + FN + TP)\n",
    "\n",
    "# Overall accuracy\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "PRE = (TP)/(TP+FP)\n",
    "REC = (TP)/(TP+FN)\n",
    "F1 = 2*(TP)/(2*TP+FP+FN)\n",
    "\n",
    "print('---Accuracy---')\n",
    "print(ACC)\n",
    "print('---Precision---')\n",
    "print(PRE)\n",
    "print('---Recall---')\n",
    "print(REC)\n",
    "print('---F1-score---')\n",
    "print(F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistakes  = FP.sum()\n",
    "mistakes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "X = X_features\n",
    "\n",
    "X_train, X_test = X[0:3579], X[3580:]\n",
    "y_train, y_test = y[0:3579], y[3580:]\n",
    "    \n",
    "class_weight = dict({0:4, 1:5, 2:4, 3:1})\n",
    "   \n",
    "rf_model = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 42, class_weight = class_weight)\n",
    "rf_model = rf_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = rf_model.predict(X_test)\n",
    "cm = ConfusionMatrix(y_test, y_pred)\n",
    "\n",
    "confusion_matrix = pd.DataFrame(data=cm.table)\n",
    "confusion_matrix.columns=['Contraindication', 'Effect', 'Relief', 'Treatment']\n",
    "confusion_matrix.index = ['Contraindication', 'Effect', 'Relief', 'Treatment']\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Accuracy\n",
    "FP = confusion_matrix.sum(axis=0) - np.diag(confusion_matrix)  \n",
    "FN = confusion_matrix.sum(axis=1) - np.diag(confusion_matrix)\n",
    "TP = np.diag(confusion_matrix)\n",
    "TN = confusion_matrix.values.sum() - (FP + FN + TP)\n",
    "\n",
    "# Overall accuracy\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "PRE = (TP)/(TP+FP)\n",
    "REC = (TP)/(TP+FN)\n",
    "F1 = 2*(TP)/(2*TP+FP+FN)\n",
    "\n",
    "print('---Accuracy---')\n",
    "print(ACC)\n",
    "print('---Precision---')\n",
    "print(PRE)\n",
    "print('---Recall---')\n",
    "print(REC)\n",
    "print('---F1-score---')\n",
    "print(F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "668"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mistakes  = FP.sum()\n",
    "mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
