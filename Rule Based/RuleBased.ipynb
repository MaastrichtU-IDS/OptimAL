{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pycm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FUNCTIONS\n",
    "\n",
    "# function for getting all the text in lower case\n",
    "def lower (x):\n",
    "    return x.lower()\n",
    "\n",
    "# remove punctuation\n",
    "def remove (x):\n",
    "    no_punct = \"\"\n",
    "    for char in x:\n",
    "            if char in '''1234567890qwertyuiopasdfghjklzxcvbnmQWERTYUIOPASDFGHJKLZXCVBNM ''':\n",
    "                    no_punct = no_punct + char\n",
    "    return no_punct\n",
    "\n",
    "\n",
    "# find the position of the targets and the patterns\n",
    "def find_position(x,str):\n",
    "    return str.find(x)\n",
    "\n",
    "# check if a phrase is in the sentence\n",
    "def check(x, str):\n",
    "    return x in str\n",
    "\n",
    "# return the position of a phrase/word in a sentence\n",
    "def pos_of_phrase(string, substring):\n",
    "    substring_length = len(substring)    \n",
    "    def recurse(locations_found, start):\n",
    "        location = string.find(substring, start)\n",
    "        if location != -1:\n",
    "            return recurse(locations_found + [location], location+substring_length)\n",
    "        else:\n",
    "            return locations_found\n",
    "\n",
    "    return recurse([], 0)\n",
    "\n",
    "# return the minimum distance of all phrase/word from the target disease\n",
    "def get_diff_of_pos(column,pos,str):\n",
    "    name = classes.columns[column]\n",
    "    my_col = classes[name]\n",
    "    x = [k for k,v in enumerate(my_col) if v == True]\n",
    "    \n",
    "    candidate = []\n",
    "    distances = []\n",
    "    for i in range(len(x)):\n",
    "        word = phrases[classes.columns[column]][x[i]]\n",
    "        \n",
    "        for i in range(len(pos_of_phrase(str, word))):\n",
    "            distances.append( abs(pos -   pos_of_phrase(str, word)[i]) )\n",
    "\n",
    "    return min(distances)\n",
    "    \n",
    "#  make all the annotations consistant   \n",
    "def rep (text):\n",
    "    a = text.replace('No consensus','IDK')\n",
    "    b = a.replace('Contraindication','contraindication')\n",
    "    c = b.replace('Effect','effect')\n",
    "    d = c.replace('Indication: Treatment', 'treatment')\n",
    "    e = d.replace('Indication: Symptomatic Relief', 'relief')\n",
    "    f = e.replace('no consensus', 'IDK')\n",
    "    return f\n",
    "\n",
    "def rep2(text):\n",
    "    a = text.replace('idk', 'IDK')\n",
    "    return a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frames of rules\n",
    "\n",
    "my_phrases = { 'effect': \n",
    "[\"hypersensitivity reactions\",\n",
    "\"associated with the risk of\",\n",
    "\"to the risk of\",\n",
    "\"a high risk for\",\n",
    "\"a high risk of\",\n",
    "\"high incidence of\", \n",
    "\"higher incidence of\", \n",
    "\" cause \",\n",
    "\" causes \",\n",
    "\"symptoms occure\",\n",
    "\"teratogenic\",\n",
    "\"site reaction\",\n",
    "\"the risk of development\",\n",
    "\"is associated with a risk of\",\n",
    "\"symptoms of the poisoning\",\n",
    "\"symptoms of poisoning\" \n",
    "],\n",
    "\n",
    " 'contraindication': \n",
    "[\"not administrated to\",\n",
    "\"contraindicated in\",\n",
    "\"contraindicatedin\",\n",
    "\"should not be used\",\n",
    "\"is contraindication for\",\n",
    "\"is contraindication when\",\n",
    "\"is contraindicated when\",\n",
    "\"must not be used for\",\n",
    "\"do not administer\",\n",
    "\"should not initiate\",\n",
    "\"not be administered to\",\n",
    "\"do not initiate patients\",\n",
    "\"contraindication for\",\n",
    "\"should not be given\",\n",
    "\"do not use\"],\n",
    "              \n",
    " 'relief': \n",
    "[\"relief of the signs\",\n",
    "\"relief of signs\",\n",
    "\"relief of symptoms\",\n",
    "\"relief of the symptoms\",\n",
    "\"help\",\n",
    "\"helps\",\n",
    "\"relief of signs and symptoms of\",\n",
    "\"reduction of symptoms of\",\n",
    "\"treatment of the symptoms of\",\n",
    "\"for the relief\",\n",
    "\"management of the signs and symptoms of\"], \n",
    "\n",
    " 'treatment':\n",
    "[\" indicated for the treatment of\",\n",
    "\" indicated in the management of\",\n",
    "\" indicated for the management of\",\n",
    "\"for the management of\",\n",
    "\"management of\",\n",
    "\" indicated for the maintenance of remission\", \n",
    "\"or the treatment of\",\n",
    "\"in the treatment of\",\n",
    "\" indicated as\",\n",
    "\" indicated in\",\n",
    "\"be effective\",\n",
    "\"active treatment of\",\n",
    "\" indicated for\",\n",
    "\"treatment of\",\n",
    "\" indicated as an adjunct\",\n",
    "\" indicated for use in the treatment of\", \n",
    "\" indicated for the intermittent treatment\", \n",
    "\" indicated to reduce the rate of\",\n",
    "\" indicated for the rapid control\",\n",
    "\" indicated for the control\",\n",
    "\"reduce the risk of\",\n",
    "\" indicated as adjunctive treatment\",\n",
    "\"for the treatment of\",\n",
    "\" indicated as an adjunct\"]\n",
    "           }\n",
    "\n",
    "phrases = pd.DataFrame({ key:pd.Series(value) for key, value in my_phrases.items() })\n",
    "\n",
    "\n",
    "effect = { 'phrases': \n",
    "[\"hypersensitivity reactions\",\n",
    "\"associated with the risk of\",\n",
    "\"to the risk of\",\n",
    "\"a high risk for\",\n",
    "\"a high risk of\",\n",
    "\"high incidence of\", \n",
    "\"higher incidence of\", \n",
    "\" cause \",\n",
    "\" causes \",\n",
    "\"symptoms occure\",\n",
    "\"teratogenic\",\n",
    "\"site reaction\",\n",
    "\"the risk of development\",\n",
    "\"is associated with a risk of\",\n",
    "\"symptoms of the poisoning\",\n",
    "\"symptoms of poisoning\" \n",
    "]}\n",
    "effect = pd.DataFrame(effect)\n",
    "\n",
    " \n",
    "contraindication = {'phrases': \n",
    "[\"not administrated to\",\n",
    "\"contraindicated in\",\n",
    "\"contraindicatedin\",\n",
    "\"should not be used\",\n",
    "\"is contraindication for\",\n",
    "\"is contraindication when\",\n",
    "\"is contraindicated when\",\n",
    "\"must not be used for\",\n",
    "\"do not administer\",\n",
    "\"should not initiate\",\n",
    "\"not be administered to\",\n",
    "\"do not initiate patients\",\n",
    "\"contraindication for\",\n",
    "\"should not be given\",\n",
    "\"do not use\"]}\n",
    "contraindication = pd.DataFrame(contraindication)\n",
    "              \n",
    "relief = {'phrases': \n",
    "[\"relief of the signs\",\n",
    "\"relief of signs\",\n",
    "\"relief of symptoms\",\n",
    "\"relief of the symptoms\",\n",
    "\"help\",\n",
    "\"helps\",\n",
    "\"relief of signs and symptoms of\",\n",
    "\"reduction of symptoms of\",\n",
    "\"treatment of the symptoms of\",\n",
    "\"for the relief\",\n",
    "\"management of the signs and symptoms of\"]} \n",
    "relief = pd.DataFrame(relief)\n",
    "\n",
    "treatment = {'phrases':\n",
    "[\" indicated for the treatment of\",\n",
    "\" indicated in the management of\",\n",
    "\" indicated for the management of\",\n",
    "\"for the management of\",\n",
    "\"management of\",\n",
    "\" indicated for the maintenance of remission\", \n",
    "\"or the treatment of\",\n",
    "\"in the treatment of\",\n",
    "\" indicated as\",\n",
    "\" indicated in\",\n",
    "\"be effective\",\n",
    "\"active treatment of\",\n",
    "\" indicated for\",\n",
    "\"treatment of\",\n",
    "\" indicated as an adjunct\",\n",
    "\" indicated for use in the treatment of\", \n",
    "\" indicated for the intermittent treatment\", \n",
    "\" indicated to reduce the rate of\",\n",
    "\" indicated for the rapid control\",\n",
    "\" indicated for the control\",\n",
    "\"reduce the risk of\",\n",
    "\" indicated as adjunctive treatment\",\n",
    "\"for the treatment of\",\n",
    "\" indicated as an adjunct\"]}\n",
    "treatment = pd.DataFrame(treatment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset\n",
    "\n",
    "df= pd.read_csv('experts_dailymed.csv')\n",
    "print('length of experts set:', len(df))\n",
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there is something missing and drop it to avoid errors\n",
    "print(df[df['DOID'].isnull()]['DOID'])\n",
    "print(df[df['DBID'].isnull()]['DBID'])\n",
    "print(df[df['text'].isnull()]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['text','disease', 'DOID',  'drug', 'DBID', 'experts', 'expert1', 'expert2', 'expert3']]\n",
    "df['label']= 'label' # create this column where the label from the model will come\n",
    "\n",
    "text = df['text']\n",
    "disease = df['disease']\n",
    "drug = df['drug']\n",
    "answer = df['experts']\n",
    "df.sample()\n",
    "\n",
    "text = text.apply(lower)\n",
    "text = text.apply(remove)\n",
    "\n",
    "disese = disease.apply(lower)\n",
    "drug = drug.apply(lower)\n",
    "\n",
    "df['expert1'] = df['expert1'].apply(rep)\n",
    "df['expert2'] = df['expert2'].apply(rep)\n",
    "df['expert3'] = df['expert3'].apply(rep)\n",
    "df['experts'] = df['experts'].apply(rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean them\n",
    "\n",
    "data = {\n",
    "'text': text,\n",
    "'drug':drug, \n",
    "'DOID': df['DOID'],\n",
    "'disease':disease, \n",
    "'DBID': df['DBID'],\n",
    "'label': 'label' , \n",
    "'expert1': df['expert1'],\n",
    "'expert2': df['expert2'],\n",
    "'expert3': df['expert3'],\n",
    "'answer': df['experts']\n",
    "} \n",
    "df1 = pd.DataFrame(data)\n",
    "\n",
    "df1.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with the cases that all experts aggree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.loc[(df1['expert1'] == df1['expert2'])  & (df1['expert1'] == df1['expert3'])].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df2)):\n",
    "    str = df2['text'][i]\n",
    "    \n",
    "\n",
    "# Find which phrases appear in the sentence\n",
    "    class_effect = effect['phrases'].apply(lambda num : check(num,str))\n",
    "    class_contraindication = contraindication['phrases'].apply(lambda num : check(num,str))\n",
    "    class_relief = relief['phrases'].apply(lambda num : check(num,str))\n",
    "    class_treatment = treatment['phrases'].apply(lambda num : check(num,str))\n",
    "\n",
    "# Create a dataset from them\n",
    "    classes = {\n",
    "    'effect': class_effect,\n",
    "    'contraindication': class_contraindication,\n",
    "    'relief': class_relief,\n",
    "    'treatment':class_treatment \n",
    "    }\n",
    "\n",
    "    classes = pd.DataFrame(classes)\n",
    "\n",
    "    a = class_effect.index[class_effect == True].tolist()\n",
    "    b = class_contraindication.index[class_contraindication == True].tolist()\n",
    "    c = class_relief.index[class_relief == True].tolist()\n",
    "    d = class_treatment.index[class_treatment == True].tolist()\n",
    "\n",
    "\n",
    "    # Check if you have unique class and label based on that \n",
    "    if len(a)!=0 and len(b)==len(c)==len(d)==0:\n",
    "        #print('effect')\n",
    "        df2['label'][i] = 'effect'\n",
    "    elif len(b)!=0 and len(a)==len(c)==len(d)==0:\n",
    "        #print('contraindication')\n",
    "        df2['label'][i] =  'contraindication'\n",
    "    elif len(c)!=0 and len(a)==len(b)==len(d)==0:\n",
    "        #print('relief')\n",
    "        df2['label'][i] = 'relief'\n",
    "    elif len(d)!=0 and len(a)==len(b)==len(c)==0:\n",
    "        #print('treatment')\n",
    "        df2['label'][i] =  'treatment'\n",
    "    elif len(a)==len(b)==len(c)==len(d)==0:\n",
    "        #print('IDK')\n",
    "        df2['label'][i] = 'IDK'\n",
    "    else: \n",
    "        pos1 = str.find(df2['disease'][i])\n",
    "        test_list = [len(a), len(b), len(c), len(d)] \n",
    "        res = [idx for idx, val in enumerate(test_list) if val != 0]\n",
    "        my_List = [get_diff_of_pos(res[j], pos1, str) for j in range(len(res))]\n",
    "        idx = my_List.index(min(my_List))\n",
    "        classes.columns[res[idx]]\n",
    "        #print(classes.columns[res[idx]])\n",
    "        df2['label'][i] =  classes.columns[res[idx]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of missclassified instances: 12\n",
      "accuracy: 0.9194630872483222\n"
     ]
    }
   ],
   "source": [
    "df2['accurate'] = (df2['label'] == df2['answer'])\n",
    "mistakes = df2['accurate'].index[ df2['accurate']== False].tolist()\n",
    "accuracy = (len(df2)-len(mistakes))/len(df2)\n",
    "print('number of missclassified instances:', len(mistakes))\n",
    "print('accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.index[df2['accurate'] == False].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycm import *\n",
    "\n",
    "pred = df2['label'].tolist()\n",
    "corr = df2 ['answer'].tolist()\n",
    "\n",
    "cm = ConfusionMatrix(pred, corr)\n",
    "\n",
    "confusion_matrix = pd.DataFrame(cm.table)\n",
    "confusion_matrix.columns=['IDK', 'contraindication', 'effect', 'relief', 'treatment']\n",
    "confusion_matrix.index = ['IDK', 'contraindication', 'effect', 'relief', 'treatment']\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Accuracy\n",
    "FP = confusion_matrix.sum(axis=0) - np.diag(confusion_matrix)  \n",
    "FN = confusion_matrix.sum(axis=1) - np.diag(confusion_matrix)\n",
    "TP = np.diag(confusion_matrix)\n",
    "TN = confusion_matrix.values.sum() - (FP + FN + TP)\n",
    "\n",
    "# Overall accuracy\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "PRE = (TP)/(TP+FP)\n",
    "REC = (TP)/(TP+FN)\n",
    "F1 = 2*(TP)/(2*TP+FP+FN)\n",
    "\n",
    "print('---Accuracy---')\n",
    "print(ACC)\n",
    "print('---Precision---')\n",
    "print(PRE)\n",
    "print('---Recall---')\n",
    "print(REC)\n",
    "print('---F1-score---')\n",
    "print(F1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with the cases that all experts aggree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df1[['text', 'drug', 'DOID', 'disease', 'DBID', 'label', 'answer']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df3)):\n",
    "    str = df3['text'][i]\n",
    "    \n",
    "\n",
    "# Find which phrases appear in the sentence\n",
    "    class_effect = effect['phrases'].apply(lambda num : check(num,str))\n",
    "    class_contraindication = contraindication['phrases'].apply(lambda num : check(num,str))\n",
    "    class_relief = relief['phrases'].apply(lambda num : check(num,str))\n",
    "    class_treatment = treatment['phrases'].apply(lambda num : check(num,str))\n",
    "\n",
    "# Create a dataset from them\n",
    "    classes = {\n",
    "    'effect': class_effect,\n",
    "    'contraindication': class_contraindication,\n",
    "    'relief': class_relief,\n",
    "    'treatment':class_treatment \n",
    "    }\n",
    "\n",
    "    classes = pd.DataFrame(classes)\n",
    "\n",
    "    a = class_effect.index[class_effect == True].tolist()\n",
    "    b = class_contraindication.index[class_contraindication == True].tolist()\n",
    "    c = class_relief.index[class_relief == True].tolist()\n",
    "    d = class_treatment.index[class_treatment == True].tolist()\n",
    "\n",
    "\n",
    "    # Check if you have unique class and label based on that \n",
    "    if len(a)!=0 and len(b)==len(c)==len(d)==0:\n",
    "        #print('effect')\n",
    "        df3['label'][i] = 'effect'\n",
    "    elif len(b)!=0 and len(a)==len(c)==len(d)==0:\n",
    "        #print('contraindication')\n",
    "        df3['label'][i] =  'contraindication'\n",
    "    elif len(c)!=0 and len(a)==len(b)==len(d)==0:\n",
    "        #print('relief')\n",
    "        df3['label'][i] = 'relief'\n",
    "    elif len(d)!=0 and len(a)==len(b)==len(c)==0:\n",
    "        #print('treatment')\n",
    "        df3['label'][i] =  'treatment'\n",
    "    elif len(a)==len(b)==len(c)==len(d)==0:\n",
    "        #print('IDK')\n",
    "        df3['label'][i] = 'IDK'\n",
    "    else: \n",
    "        pos1 = str.find(df3['disease'][i])\n",
    "        test_list = [len(a), len(b), len(c), len(d)] \n",
    "        res = [idx for idx, val in enumerate(test_list) if val != 0]\n",
    "        my_List = [get_diff_of_pos(res[j], pos1, str) for j in range(len(res))]\n",
    "        idx = my_List.index(min(my_List))\n",
    "        classes.columns[res[idx]]\n",
    "        #print(classes.columns[res[idx]])\n",
    "        df3['label'][i] =  classes.columns[res[idx]]\n",
    "\n",
    "df3.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of missclassified instances: 109\n",
      "accuracy: 0.6955307262569832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristshingjergji/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df3['accurate'] = (df3['label'] == df3['answer'])\n",
    "mistakes = df3['accurate'].index[ df3['accurate']== False].tolist()\n",
    "accuracy = (len(df3)-len(mistakes))/len(df3)\n",
    "print('number of missclassified instances:', len(mistakes))\n",
    "print('accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 ['answer']= df3 ['answer'].apply(rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df3.index[df3['accurate'] == False].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idk</th>\n",
       "      <th>contraindication</th>\n",
       "      <th>effect</th>\n",
       "      <th>relief</th>\n",
       "      <th>treatment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>idk</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contraindication</th>\n",
       "      <td>9</td>\n",
       "      <td>78</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>effect</th>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relief</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treatment</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  idk  contraindication  effect  relief  treatment\n",
       "idk                 5                12       2       0          9\n",
       "contraindication    9                78      19       0          1\n",
       "effect              6                14      22       0          5\n",
       "relief              0                 3       0      30         16\n",
       "treatment           1                 2       9       1        114"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = df3['label'].tolist()\n",
    "corr = df3 ['answer'].tolist()\n",
    "\n",
    "cm = ConfusionMatrix(pred, corr)\n",
    "confusion_matrix = pd.DataFrame(cm.table)\n",
    "confusion_matrix.columns=['idk', 'contraindication', 'effect', 'relief', 'treatment']\n",
    "confusion_matrix.index = ['idk', 'contraindication', 'effect', 'relief', 'treatment']\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Accuracy\n",
    "FP = confusion_matrix.sum(axis=0) - np.diag(confusion_matrix)  \n",
    "FN = confusion_matrix.sum(axis=1) - np.diag(confusion_matrix)\n",
    "TP = np.diag(confusion_matrix)\n",
    "TN = confusion_matrix.values.sum() - (FP + FN + TP)\n",
    "\n",
    "# Overall accuracy\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "PRE = (TP)/(TP+FP)\n",
    "REC = (TP)/(TP+FN)\n",
    "F1 = 2*(TP)/(2*TP+FP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('---Accuracy---')\n",
    "print(ACC)\n",
    "print('---Precision---')\n",
    "print(PRE)\n",
    "print('---Recall---')\n",
    "print(REC)\n",
    "print('---F1-score---')\n",
    "print(F1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with at least one expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = df1[['text', 'drug', 'DOID', 'disease', 'DBID', 'expert1', 'expert2', 'expert3','label']]\n",
    "df6['expert1'] = df6['expert1'].apply(rep2)\n",
    "df6['expert2'] = df6['expert2'].apply(rep2)\n",
    "df6['expert3'] = df6['expert3'].apply(rep2)\n",
    "df6['at_least'] = df6['expert3'].apply(rep2) # here will go the True/False of prediction being the same  with at least one expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df6)):\n",
    "    str = df6['text'][i]\n",
    "    \n",
    "\n",
    "# Find which phrases appear in the sentence\n",
    "    class_effect = effect['phrases'].apply(lambda num : check(num,str))\n",
    "    class_contraindication = contraindication['phrases'].apply(lambda num : check(num,str))\n",
    "    class_relief = relief['phrases'].apply(lambda num : check(num,str))\n",
    "    class_treatment = treatment['phrases'].apply(lambda num : check(num,str))\n",
    "\n",
    "# Create a dataset from them\n",
    "    classes = {\n",
    "    'effect': class_effect,\n",
    "    'contraindication': class_contraindication,\n",
    "    'relief': class_relief,\n",
    "    'treatment':class_treatment \n",
    "    }\n",
    "\n",
    "    classes = pd.DataFrame(classes)\n",
    "\n",
    "    a = class_effect.index[class_effect == True].tolist()\n",
    "    b = class_contraindication.index[class_contraindication == True].tolist()\n",
    "    c = class_relief.index[class_relief == True].tolist()\n",
    "    d = class_treatment.index[class_treatment == True].tolist()\n",
    "\n",
    "\n",
    "    # Check if you have unique class and label based on that \n",
    "    if len(a)!=0 and len(b)==len(c)==len(d)==0:\n",
    "        #print('effect')\n",
    "        df6['label'][i] = 'effect'\n",
    "    elif len(b)!=0 and len(a)==len(c)==len(d)==0:\n",
    "        #print('contraindication')\n",
    "        df6['label'][i] =  'contraindication'\n",
    "    elif len(c)!=0 and len(a)==len(b)==len(d)==0:\n",
    "        #print('relief')\n",
    "        df6['label'][i] = 'relief'\n",
    "    elif len(d)!=0 and len(a)==len(b)==len(c)==0:\n",
    "        #print('treatment')\n",
    "        df6['label'][i] =  'treatment'\n",
    "    elif len(a)==len(b)==len(c)==len(d)==0:\n",
    "        #print('IDK')\n",
    "        df6['label'][i] = 'IDK'\n",
    "    else: \n",
    "        pos1 = str.find(df6['disease'][i])\n",
    "        test_list = [len(a), len(b), len(c), len(d)] \n",
    "        res = [idx for idx, val in enumerate(test_list) if val != 0]\n",
    "        my_List = [get_diff_of_pos(res[j], pos1, str) for j in range(len(res))]\n",
    "        idx = my_List.index(min(my_List))\n",
    "        classes.columns[res[idx]]\n",
    "        #print(classes.columns[res[idx]])\n",
    "        df6['label'][i] =  classes.columns[res[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df6)):\n",
    "    if df6['label'][i] == df6['expert1'][i]:\n",
    "        df6['at_least'][i] = True\n",
    "    elif df6['label'][i] == df6['expert2'][i]:\n",
    "        df6['at_least'][i] = True\n",
    "    elif df['label'][i] == df6['expert3'][i]:\n",
    "        df6['at_least'][i] =True\n",
    "    else:\n",
    "        df6['at_least'][i] = False  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>drug</th>\n",
       "      <th>DOID</th>\n",
       "      <th>disease</th>\n",
       "      <th>DBID</th>\n",
       "      <th>expert1</th>\n",
       "      <th>expert2</th>\n",
       "      <th>expert3</th>\n",
       "      <th>label</th>\n",
       "      <th>at_least</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>felodipine extendedrelease tablets uspare indi...</td>\n",
       "      <td>felodipine</td>\n",
       "      <td>DOID_5844</td>\n",
       "      <td>myocardial infarction</td>\n",
       "      <td>DB01023</td>\n",
       "      <td>treatment</td>\n",
       "      <td>treatment</td>\n",
       "      <td>effect</td>\n",
       "      <td>treatment</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text        drug       DOID  \\\n",
       "294  felodipine extendedrelease tablets uspare indi...  felodipine  DOID_5844   \n",
       "\n",
       "                   disease     DBID    expert1    expert2 expert3      label  \\\n",
       "294  myocardial infarction  DB01023  treatment  treatment  effect  treatment   \n",
       "\n",
       "    at_least  \n",
       "294     True  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of missclassified instances: 76\n",
      "accuracy: 0.7877094972067039\n"
     ]
    }
   ],
   "source": [
    "mistakes = df6['at_least'].index[ df6['at_least']== False].tolist()\n",
    "accuracy = (len(df6)-len(mistakes))/len(df6)\n",
    "print('number of missclassified instances:', len(mistakes))\n",
    "print('accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crowd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of experts set: 4046\n"
     ]
    }
   ],
   "source": [
    "df4= pd.read_csv('crowd_dailymed.csv')\n",
    "print('length of experts set:', len(df4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>drug</th>\n",
       "      <th>DOID</th>\n",
       "      <th>disease</th>\n",
       "      <th>DBID</th>\n",
       "      <th>label</th>\n",
       "      <th>crowd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2805</th>\n",
       "      <td>['Caffeine citrate injection and caffeine citr...</td>\n",
       "      <td>Caffeine</td>\n",
       "      <td>DOID_1205</td>\n",
       "      <td>allergic hypersensitivity disease</td>\n",
       "      <td>DB00201</td>\n",
       "      <td>label</td>\n",
       "      <td>relief</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text      drug       DOID  \\\n",
       "2805  ['Caffeine citrate injection and caffeine citr...  Caffeine  DOID_1205   \n",
       "\n",
       "                                disease     DBID  label   crowd  \n",
       "2805  allergic hypersensitivity disease  DB00201  label  relief  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "'text': df4['text'],\n",
    "'drug': df4['drug'], \n",
    "'DOID': df4['DOID'],\n",
    "'disease': df4['disease'], \n",
    "'DBID': df4['DBID'],\n",
    "'label': 'label' , \n",
    "'crowd': df4['relation']\n",
    "} \n",
    "\n",
    "df5 = pd.DataFrame(data)\n",
    "\n",
    "df5.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df5)):\n",
    "    str = df5['text'][i]\n",
    "    \n",
    "# Find which phrases appear in the sentence\n",
    "    class_effect = effect['phrases'].apply(lambda num : check(num,str))\n",
    "    class_contraindication = contraindication['phrases'].apply(lambda num : check(num,str))\n",
    "    class_relief = relief['phrases'].apply(lambda num : check(num,str))\n",
    "    class_treatment = treatment['phrases'].apply(lambda num : check(num,str))\n",
    "\n",
    "# Create a dataset from them\n",
    "    classes = {\n",
    "    'effect': class_effect,\n",
    "    'contraindication': class_contraindication,\n",
    "    'relief': class_relief,\n",
    "    'treatment':class_treatment \n",
    "    }\n",
    "\n",
    "    classes = pd.DataFrame(classes)\n",
    "\n",
    "    a = class_effect.index[class_effect == True].tolist()\n",
    "    b = class_contraindication.index[class_contraindication == True].tolist()\n",
    "    c = class_relief.index[class_relief == True].tolist()\n",
    "    d = class_treatment.index[class_treatment == True].tolist()\n",
    "\n",
    "\n",
    "    # Check if you have unique class and label based on that \n",
    "    if len(a)!=0 and len(b)==len(c)==len(d)==0:\n",
    "        #print('effect')\n",
    "        df5['label'][i] = 'effect'\n",
    "    elif len(b)!=0 and len(a)==len(c)==len(d)==0:\n",
    "        #print('contraindication')\n",
    "        df5['label'][i] =  'contraindication'\n",
    "    elif len(c)!=0 and len(a)==len(b)==len(d)==0:\n",
    "        #print('relief')\n",
    "        df5['label'][i] = 'relief'\n",
    "    elif len(d)!=0 and len(a)==len(b)==len(c)==0:\n",
    "        #print('treatment')\n",
    "        df5['label'][i] =  'treatment'\n",
    "    elif len(a)==len(b)==len(c)==len(d)==0:\n",
    "        #print('IDK')\n",
    "        df5['label'][i] = 'IDK'\n",
    "    else: \n",
    "        pos1 = str.find(df5['disease'][i])\n",
    "        test_list = [len(a), len(b), len(c), len(d)] \n",
    "        res = [idx for idx, val in enumerate(test_list) if val != 0]\n",
    "        my_List = [get_diff_of_pos(res[j], pos1, str) for j in range(len(res))]\n",
    "        idx = my_List.index(min(my_List))\n",
    "        classes.columns[res[idx]]\n",
    "        #print(classes.columns[res[idx]])\n",
    "        df5['label'][i] =  classes.columns[res[idx]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of missclassified instances: 1519\n",
      "accuracy: 0.6245674740484429\n"
     ]
    }
   ],
   "source": [
    "df5['accurate'] = (df5['label'] == df5['crowd'])\n",
    "mistakes = df5['accurate'].index[ df5['accurate']== False].tolist()\n",
    "accuracy = (len(df5)-len(mistakes))/len(df5)\n",
    "print('number of missclassified instances:', len(mistakes))\n",
    "print('accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = df5['label'].tolist()\n",
    "corr = df5 ['crowd'].tolist()\n",
    "\n",
    "cm = ConfusionMatrix(pred, corr)\n",
    "confusion_matrix = pd.DataFrame(cm.table)\n",
    "confusion_matrix.columns=['IDK', 'contraindication', 'effect', 'relief', 'treatment']\n",
    "confusion_matrix.index = ['IDK', 'contraindication', 'effect', 'relief', 'treatment']\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Accuracy\n",
    "FP = confusion_matrix.sum(axis=0) - np.diag(confusion_matrix)  \n",
    "FN = confusion_matrix.sum(axis=1) - np.diag(confusion_matrix)\n",
    "TP = np.diag(confusion_matrix)\n",
    "TN = confusion_matrix.values.sum() - (FP + FN + TP)\n",
    "\n",
    "# Overall accuracy\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "PRE = (TP)/(TP+FP)\n",
    "REC = (TP)/(TP+FN)\n",
    "F1 = 2*(TP)/(2*TP+FP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('---Accuracy---')\n",
    "print(ACC)\n",
    "print('---Precision---')\n",
    "print(PRE)\n",
    "print('---Recall---')\n",
    "print(REC)\n",
    "print('---F1-score---')\n",
    "print(F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
