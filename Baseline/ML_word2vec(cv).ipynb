{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data set\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv('crowd_final.csv')\n",
    "data = data.drop(data[data['relation']== 'IDK'].index).reset_index()\n",
    "data['relation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[data['text'].isnull()]['text'])\n",
    "print(data[data['relation'].isnull()]['relation'])\n",
    "print(data[data['DOID'].isnull()]['DOID'])\n",
    "print(data[data['DBID'].isnull()]['DBID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text =  data['text']\n",
    "labels = data['relation']\n",
    "disease = data['DOID']\n",
    "drug = data['DBID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for cleaning \n",
    "\n",
    "def remove (x):\n",
    "    no_punct = \"\"\n",
    "    for char in x:\n",
    "            if char in '''qwertyuiopasdfghjklzxcvbnmQWERTYUIOPASDFGHJKLZXCVBNM ''':\n",
    "                    no_punct = no_punct + char\n",
    "    return no_punct\n",
    "\n",
    "def remove_non_digits (x):\n",
    "    no_punct = \"\"\n",
    "    for char in x:\n",
    "            if char in '''1234567890qwertyuiopasdfghjklzxcvbnmQWERTYUIOPASDFGHJKLZXCVBNM ''':\n",
    "                    no_punct = no_punct + char\n",
    "    return no_punct\n",
    "\n",
    "def lower (x):\n",
    "    return x.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['contraindication'] is encoded as 0\n",
      "['effect'] is encoded as 1\n",
      "['relief'] is encoded as 2\n",
      "['treatment'] is encoded as 3\n"
     ]
    }
   ],
   "source": [
    "# --- Encode Labels ---\n",
    "\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(data['relation'])\n",
    "le.classes_\n",
    "labels_en = le.transform(data['relation']) \n",
    "\n",
    "# Check the encoding\n",
    "\n",
    "zero = list(le.inverse_transform([0]))\n",
    "one = list(le.inverse_transform([1]))\n",
    "two = list(le.inverse_transform([2]))\n",
    "three = list(le.inverse_transform([3]))\n",
    "\n",
    "print(zero, 'is encoded as 0')\n",
    "print(one, 'is encoded as 1')\n",
    "print(two, 'is encoded as 2')\n",
    "print(three, 'is encoded as 3')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Encode Drugs ---\n",
    "\n",
    "le.fit(data['DBID'])\n",
    "le.classes_\n",
    "drug_labbeled = le.transform(data['DBID']) \n",
    "\n",
    "# --- Encode Disease ---\n",
    "\n",
    "le.fit(data['DOID'])\n",
    "le.classes_\n",
    "disease_labbeled = le.transform(data['DOID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Remove stop words and clean the Text ---\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "data['text'] = data['text'].apply(remove)\n",
    "data['text'] = data['text'].apply(lower)\n",
    "\n",
    "def remove_stopwords(sentence):\n",
    "    word_tokens = word_tokenize(sentence)\n",
    "    filtered_sentence = []\n",
    "    for w in word_tokens:\n",
    "        if w not in stop_words and len(w)>=2:\n",
    "            filtered_sentence.append(w)\n",
    "    return filtered_sentence\n",
    "\n",
    "corpus = data['text'].apply(remove_stopwords)\n",
    "\n",
    "# New Data Frame with tokenized and clean sentences\n",
    "d = {'label': labels_en, 'text': corpus, 'disease': disease_labbeled, 'drug':drug_labbeled}\n",
    "df = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec\n",
    "import gensim\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the labels \n",
    "y = labels_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model of vector representation\n",
    "model = Word2Vec(sentences = corpus, size = 100, sg = 1, window = 3, \n",
    "                 min_count = 1, iter = 10, workers = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the initial df so that we work on that \n",
    "df_en = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each instance/sentence compute the average of all the words \n",
    "\n",
    "def avg_vector(list_of_words):\n",
    "    vector_sum = model.wv[list_of_words[0]]\n",
    "    for i in range(1,len(list_of_words)):\n",
    "        vector_sum = vector_sum +  model.wv[list_of_words[i]]\n",
    "    return vector_sum/len(list_of_words)\n",
    "\n",
    "df_en['text'] = df_en['text'].apply(avg_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data frame with the embedded text\n",
    "d2 = {'label': y, 'text':df_en['text'] , 'disease': disease_labbeled, 'drug':drug_labbeled}\n",
    "df2 = pd.DataFrame(data=d2)\n",
    "embedded = df2.to_csv('embedded.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the features\n",
    "\n",
    "X_features = []\n",
    "for i in range(len(df_en['text'])):\n",
    "    a = df_en['text'][i].tolist()\n",
    "    b = int(drug_labbeled[i])\n",
    "    c = int(disease_labbeled[i])\n",
    "    a.append(b)\n",
    "    d = a\n",
    "    d.append(c)\n",
    "    e = d\n",
    "    X_features.append(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_embedding import BertEmbedding\n",
    "bert_embedding = BertEmbedding()\n",
    "\n",
    "def get_embeddings (sentence):\n",
    "    result = bert_embedding(sentence)\n",
    "    average_vec = result[0][1][0]\n",
    "    for i in range(1,len(result)):\n",
    "        average_vec = np.add(average_vec,result[i][1][0])\n",
    "    return average_vec/len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0\n",
      "2 1\n",
      "3 2\n",
      "4 3\n",
      "5 4\n",
      "6 5\n",
      "7 6\n",
      "8 7\n",
      "9 8\n",
      "10 9\n",
      "11 10\n",
      "12 11\n",
      "13 12\n",
      "14 13\n",
      "15 14\n",
      "16 15\n",
      "17 16\n",
      "18 17\n",
      "19 18\n",
      "20 19\n",
      "21 20\n",
      "22 21\n",
      "23 22\n",
      "24 23\n",
      "25 24\n",
      "26 25\n",
      "27 26\n",
      "28 27\n",
      "29 28\n",
      "30 29\n",
      "31 30\n",
      "32 31\n",
      "33 32\n",
      "34 33\n",
      "35 34\n",
      "36 35\n",
      "37 36\n",
      "38 37\n",
      "39 38\n",
      "40 39\n",
      "41 40\n",
      "42 41\n",
      "43 42\n",
      "44 43\n",
      "45 44\n",
      "46 45\n",
      "47 46\n",
      "48 47\n",
      "49 48\n",
      "50 49\n",
      "51 50\n",
      "52 51\n",
      "53 52\n",
      "54 53\n",
      "55 54\n",
      "56 55\n",
      "57 56\n",
      "58 57\n",
      "59 58\n",
      "60 59\n",
      "61 60\n",
      "62 61\n",
      "63 62\n",
      "64 63\n",
      "65 64\n",
      "66 65\n",
      "67 66\n",
      "68 67\n",
      "69 68\n",
      "70 69\n",
      "71 70\n",
      "72 71\n",
      "73 72\n",
      "74 73\n",
      "75 74\n",
      "76 75\n",
      "77 76\n",
      "78 77\n",
      "79 78\n",
      "80 79\n",
      "81 80\n",
      "82 81\n",
      "83 82\n",
      "84 83\n",
      "85 84\n",
      "86 85\n",
      "87 86\n",
      "88 87\n",
      "89 88\n",
      "90 89\n",
      "91 90\n",
      "92 91\n",
      "93 92\n",
      "94 93\n",
      "95 94\n",
      "96 95\n",
      "97 96\n",
      "98 97\n",
      "99 98\n",
      "100 99\n",
      "101 100\n",
      "102 101\n",
      "103 102\n",
      "104 103\n",
      "105 104\n",
      "106 105\n",
      "107 106\n",
      "108 107\n",
      "109 108\n",
      "110 109\n",
      "111 110\n",
      "112 111\n",
      "113 112\n",
      "114 113\n",
      "115 114\n",
      "116 115\n",
      "117 116\n",
      "118 117\n",
      "119 118\n",
      "120 119\n",
      "121 120\n",
      "122 121\n",
      "123 122\n",
      "124 123\n",
      "125 124\n",
      "126 125\n",
      "127 126\n",
      "128 127\n",
      "129 128\n",
      "130 129\n",
      "131 130\n",
      "132 131\n",
      "133 132\n",
      "134 133\n",
      "135 134\n",
      "136 135\n",
      "137 136\n",
      "138 137\n",
      "139 138\n",
      "140 139\n",
      "141 140\n",
      "142 141\n",
      "143 142\n",
      "144 143\n",
      "145 144\n",
      "146 145\n",
      "147 146\n",
      "148 147\n",
      "149 148\n",
      "150 149\n",
      "151 150\n",
      "152 151\n",
      "153 152\n",
      "154 153\n",
      "155 154\n",
      "156 155\n",
      "157 156\n",
      "158 157\n",
      "159 158\n",
      "160 159\n",
      "161 160\n",
      "162 161\n",
      "163 162\n",
      "164 163\n",
      "165 164\n",
      "166 165\n",
      "167 166\n",
      "168 167\n",
      "169 168\n",
      "170 169\n",
      "171 170\n",
      "172 171\n",
      "173 172\n",
      "174 173\n",
      "175 174\n",
      "176 175\n",
      "177 176\n",
      "178 177\n",
      "179 178\n",
      "180 179\n",
      "181 180\n",
      "182 181\n",
      "183 182\n",
      "184 183\n",
      "185 184\n",
      "186 185\n",
      "187 186\n",
      "188 187\n",
      "189 188\n",
      "190 189\n",
      "191 190\n",
      "192 191\n",
      "193 192\n",
      "194 193\n",
      "195 194\n",
      "196 195\n",
      "197 196\n",
      "198 197\n",
      "199 198\n",
      "200 199\n",
      "201 200\n",
      "202 201\n",
      "203 202\n",
      "204 203\n",
      "205 204\n",
      "206 205\n",
      "207 206\n",
      "208 207\n",
      "209 208\n",
      "210 209\n",
      "211 210\n",
      "212 211\n",
      "213 212\n",
      "214 213\n",
      "215 214\n",
      "216 215\n",
      "217 216\n",
      "218 217\n",
      "219 218\n",
      "220 219\n",
      "221 220\n",
      "222 221\n",
      "223 222\n",
      "224 223\n",
      "225 224\n",
      "226 225\n",
      "227 226\n",
      "228 227\n",
      "229 228\n",
      "230 229\n",
      "231 230\n",
      "232 231\n",
      "233 232\n",
      "234 233\n",
      "235 234\n",
      "236 235\n",
      "237 236\n",
      "238 237\n",
      "239 238\n",
      "240 239\n",
      "241 240\n",
      "242 241\n",
      "243 242\n",
      "244 243\n",
      "245 244\n",
      "246 245\n",
      "247 246\n",
      "248 247\n",
      "249 248\n",
      "250 249\n",
      "251 250\n",
      "252 251\n",
      "253 252\n",
      "254 253\n",
      "255 254\n",
      "256 255\n",
      "257 256\n",
      "258 257\n",
      "259 258\n",
      "260 259\n",
      "261 260\n",
      "262 261\n",
      "263 262\n",
      "264 263\n",
      "265 264\n",
      "266 265\n",
      "267 266\n",
      "268 267\n",
      "269 268\n",
      "270 269\n",
      "271 270\n",
      "272 271\n",
      "273 272\n",
      "274 273\n",
      "275 274\n",
      "276 275\n",
      "277 276\n",
      "278 277\n",
      "279 278\n",
      "280 279\n",
      "281 280\n",
      "282 281\n",
      "283 282\n",
      "284 283\n",
      "285 284\n",
      "286 285\n",
      "287 286\n",
      "288 287\n",
      "289 288\n",
      "290 289\n"
     ]
    }
   ],
   "source": [
    "final_bert= pd.DataFrame()\n",
    "count = 0\n",
    "\n",
    "for i in range(len(df['text'])):\n",
    "    count = count +1\n",
    "    print(count,i)\n",
    "    final_bert[i]= get_embeddings(corpus[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Plotting\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm \n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import pycm\n",
    "from pycm import *\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "X = scaler.fit_transform(X_features)\n",
    "#X = X_features #or not scaled\n",
    "\n",
    "all_cm = []\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    class_weight = dict({0:4, 1:5, 2:4, 3:1})\n",
    "    #, class_weight = class_weight\n",
    "    \n",
    "    \n",
    "    model = svm.SVC(gamma= 'scale', class_weight = class_weight)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    cm = ConfusionMatrix(y_pred, y_test)\n",
    "    \n",
    "    all_cm.append(cm)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Contraindication</th>\n",
       "      <th>Effect</th>\n",
       "      <th>Relief</th>\n",
       "      <th>Treatment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Contraindication</th>\n",
       "      <td>275</td>\n",
       "      <td>48</td>\n",
       "      <td>97</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Effect</th>\n",
       "      <td>40</td>\n",
       "      <td>146</td>\n",
       "      <td>44</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relief</th>\n",
       "      <td>108</td>\n",
       "      <td>40</td>\n",
       "      <td>321</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Treatment</th>\n",
       "      <td>155</td>\n",
       "      <td>143</td>\n",
       "      <td>182</td>\n",
       "      <td>1884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Contraindication  Effect  Relief  Treatment\n",
       "Contraindication               275      48      97         34\n",
       "Effect                          40     146      44         28\n",
       "Relief                         108      40     321         34\n",
       "Treatment                      155     143     182       1884"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the different confusion matrices from the k validation sets\n",
    "\n",
    "confusion_matrix = pd.DataFrame()\n",
    "for i in range(len(all_cm)):\n",
    "      confusion_matrix= confusion_matrix.append(pd.DataFrame(all_cm[i].table))\n",
    "        \n",
    "confusion_matrix = confusion_matrix.groupby(confusion_matrix.index).sum()\n",
    "confusion_matrix.columns=['Contraindication', 'Effect', 'Relief', 'Treatment']\n",
    "confusion_matrix.index = ['Contraindication', 'Effect', 'Relief', 'Treatment']\n",
    "confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Accuracy---\n",
      "Contraindication    0.865326\n",
      "Effect              0.904163\n",
      "Relief              0.858899\n",
      "Treatment           0.839061\n",
      "dtype: float64\n",
      "---Precision---\n",
      "Contraindication    0.475779\n",
      "Effect              0.387268\n",
      "Relief              0.498447\n",
      "Treatment           0.951515\n",
      "dtype: float64\n",
      "---Recall---\n",
      "Contraindication    0.605727\n",
      "Effect              0.565891\n",
      "Relief              0.638171\n",
      "Treatment           0.796954\n",
      "dtype: float64\n",
      "---F1-score---\n",
      "Contraindication    0.532946\n",
      "Effect              0.459843\n",
      "Relief              0.559721\n",
      "Treatment           0.867403\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Metrics from confusion matrix\n",
    "FP = confusion_matrix.sum(axis=0) - np.diag(confusion_matrix)  \n",
    "FN = confusion_matrix.sum(axis=1) - np.diag(confusion_matrix)\n",
    "TP = np.diag(confusion_matrix)\n",
    "TN = confusion_matrix.values.sum() - (FP + FN + TP)\n",
    "\n",
    "# Overall accuracy\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "PRE = (TP)/(TP+FP)\n",
    "REC = (TP)/(TP+FN)\n",
    "F1 = 2*(TP)/(2*TP+FP+FN)\n",
    "\n",
    "\n",
    "print('---Accuracy---')\n",
    "print(ACC)\n",
    "print('---Precision---')\n",
    "print(PRE)\n",
    "print('---Recall---')\n",
    "print(REC)\n",
    "print('---F1-score---')\n",
    "print(F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "953"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mistakes  = FP.sum()\n",
    "mistakes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from pycm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5)\n",
    "dt_model = DecisionTreeClassifier()\n",
    "\n",
    "X = scaler.fit_transform(X_features)\n",
    "#X = X_features\n",
    "all_cm = []\n",
    "\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    #print (len(X_train), len(X_test))\n",
    "    class_weight = dict({0:4, 1:5, 2:4, 3:1})\n",
    "    #, class_weight = class_weight\n",
    "    \n",
    "    \n",
    "    dt_model = DecisionTreeClassifier( criterion = 'entropy', random_state = 42)\n",
    "    dt_model = dt_model.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    y_pred = dt_model.predict(X_test)\n",
    "    \n",
    "    cm = ConfusionMatrix(y_test, y_pred)\n",
    "    \n",
    "    all_cm.append(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Contraindication</th>\n",
       "      <th>Effect</th>\n",
       "      <th>Relief</th>\n",
       "      <th>Treatment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Contraindication</th>\n",
       "      <td>261</td>\n",
       "      <td>41</td>\n",
       "      <td>67</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Effect</th>\n",
       "      <td>31</td>\n",
       "      <td>162</td>\n",
       "      <td>36</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relief</th>\n",
       "      <td>80</td>\n",
       "      <td>22</td>\n",
       "      <td>323</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Treatment</th>\n",
       "      <td>82</td>\n",
       "      <td>33</td>\n",
       "      <td>77</td>\n",
       "      <td>2113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Contraindication  Effect  Relief  Treatment\n",
       "Contraindication               261      41      67         83\n",
       "Effect                          31     162      36         54\n",
       "Relief                          80      22     323        114\n",
       "Treatment                       82      33      77       2113"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the different confusion matrices from the k validation sets\n",
    "\n",
    "confusion_matrix = pd.DataFrame()\n",
    "for i in range(len(all_cm)):\n",
    "      confusion_matrix= confusion_matrix.append(pd.DataFrame(all_cm[i].table))\n",
    "        \n",
    "confusion_matrix = confusion_matrix.groupby(confusion_matrix.index).sum()\n",
    "confusion_matrix.columns=['Contraindication', 'Effect', 'Relief', 'Treatment']\n",
    "confusion_matrix.index = ['Contraindication', 'Effect', 'Relief', 'Treatment']\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics from confusion matrix\n",
    "FP = confusion_matrix.sum(axis=0) - np.diag(confusion_matrix)  \n",
    "FN = confusion_matrix.sum(axis=1) - np.diag(confusion_matrix)\n",
    "TP = np.diag(confusion_matrix)\n",
    "TN = confusion_matrix.values.sum() - (FP + FN + TP)\n",
    "\n",
    "# Overall accuracy\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "PRE = (TP)/(TP+FP)\n",
    "REC = (TP)/(TP+FN)\n",
    "F1 = 2*(TP)/(2*TP+FP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Accuracy---\n",
      "Contraindication    0.892707\n",
      "Effect              0.939369\n",
      "Relief              0.889355\n",
      "Treatment           0.876222\n",
      "dtype: float64\n",
      "---Precision---\n",
      "Contraindication    0.574890\n",
      "Effect              0.627907\n",
      "Relief              0.642147\n",
      "Treatment           0.893824\n",
      "dtype: float64\n",
      "---Recall---\n",
      "Contraindication    0.577434\n",
      "Effect              0.572438\n",
      "Relief              0.599258\n",
      "Treatment           0.916703\n",
      "dtype: float64\n",
      "---F1-score---\n",
      "Contraindication    0.576159\n",
      "Effect              0.598891\n",
      "Relief              0.619962\n",
      "Treatment           0.905119\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('---Accuracy---')\n",
    "print(ACC)\n",
    "print('---Precision---')\n",
    "print(PRE)\n",
    "print('---Recall---')\n",
    "print(REC)\n",
    "print('---F1-score---')\n",
    "print(F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "720"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mistakes  = FP.sum()\n",
    "mistakes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "X = scaler.fit_transform(X_features)\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "#X = X_features\n",
    "all_cm = []\n",
    "\n",
    "\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    #print (len(X_train), len(X_test))\n",
    "    \n",
    "    class_weight = dict({0:4, 1:5, 2:4, 3:1})\n",
    "    #, class_weight = class_weight\n",
    "    \n",
    "    rf_model = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 42)\n",
    "   \n",
    "    rf_model = rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    cm = ConfusionMatrix(y_test, y_pred)\n",
    "    \n",
    "    all_cm.append(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Contraindication</th>\n",
       "      <th>Effect</th>\n",
       "      <th>Relief</th>\n",
       "      <th>Treatment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Contraindication</th>\n",
       "      <td>248</td>\n",
       "      <td>42</td>\n",
       "      <td>94</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Effect</th>\n",
       "      <td>27</td>\n",
       "      <td>148</td>\n",
       "      <td>22</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relief</th>\n",
       "      <td>81</td>\n",
       "      <td>21</td>\n",
       "      <td>302</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Treatment</th>\n",
       "      <td>98</td>\n",
       "      <td>47</td>\n",
       "      <td>85</td>\n",
       "      <td>2112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Contraindication  Effect  Relief  Treatment\n",
       "Contraindication               248      42      94        109\n",
       "Effect                          27     148      22         52\n",
       "Relief                          81      21     302         91\n",
       "Treatment                       98      47      85       2112"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the different confusion matrices from the k validation sets\n",
    "\n",
    "confusion_matrix = pd.DataFrame()\n",
    "for i in range(len(all_cm)):\n",
    "      confusion_matrix= confusion_matrix.append(pd.DataFrame(all_cm[i].table))\n",
    "        \n",
    "confusion_matrix = confusion_matrix.groupby(confusion_matrix.index).sum()\n",
    "confusion_matrix.columns=['Contraindication', 'Effect', 'Relief', 'Treatment']\n",
    "confusion_matrix.index = ['Contraindication', 'Effect', 'Relief', 'Treatment']\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Accuracy---\n",
      "Contraindication    0.873987\n",
      "Effect              0.941045\n",
      "Relief              0.889913\n",
      "Treatment           0.865326\n",
      "dtype: float64\n",
      "---Precision---\n",
      "Contraindication    0.546256\n",
      "Effect              0.573643\n",
      "Relief              0.600398\n",
      "Treatment           0.893401\n",
      "dtype: float64\n",
      "---Recall---\n",
      "Contraindication    0.503043\n",
      "Effect              0.594378\n",
      "Relief              0.610101\n",
      "Treatment           0.901793\n",
      "dtype: float64\n",
      "---F1-score---\n",
      "Contraindication    0.523759\n",
      "Effect              0.583826\n",
      "Relief              0.605210\n",
      "Treatment           0.897578\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Compute Accuracy\n",
    "FP = confusion_matrix.sum(axis=0) - np.diag(confusion_matrix)  \n",
    "FN = confusion_matrix.sum(axis=1) - np.diag(confusion_matrix)\n",
    "TP = np.diag(confusion_matrix)\n",
    "TN = confusion_matrix.values.sum() - (FP + FN + TP)\n",
    "\n",
    "# Overall accuracy\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "PRE = (TP)/(TP+FP)\n",
    "REC = (TP)/(TP+FN)\n",
    "F1 = 2*(TP)/(2*TP+FP+FN)\n",
    "\n",
    "print('---Accuracy---')\n",
    "print(ACC)\n",
    "print('---Precision---')\n",
    "print(PRE)\n",
    "print('---Recall---')\n",
    "print(REC)\n",
    "print('---F1-score---')\n",
    "print(F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "769"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mistakes  = FP.sum()\n",
    "mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
